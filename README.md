# BUDDY
First Aid for Mental Health - Your Friend in Need and Your Friend Indeed

**BUDDY** is an AI-powered mental health assistant designed to provide users with emotional triage, supportive feedback, and personalized interactions. Whether you just need a friend or are facing something more serious, BUDDY is here to listen, support, and guide you — without judgment, without pressure, anytime you need it.

Built during Auraria Hack 2025, the app offers an accessible, stigma-free space to express how you feel, receive uplifting responses, and understand when it might be time to seek help.

---

## Features

-  **Voice Input Support** – Speak how you’re feeling, and the assistant transcribes and responds
-  **Emotion-Based Response Generator** – Get thoughtful, sometimes humorous feedback tailored to your mood
-  **Voice-Activated Journaling** – Say “journal” to begin recording your thoughts, then save them to a file
-  **Avatar Generator** – Create a visual that matches your emotional vibe using DiceBear
-  **Dark/Light Mode Toggle** – Includes themed UI graphics
-  **Risk Awareness** – Responses are designed to differentiate casual emotions from potentially serious ones

---

## How to Use

1. Clone the repo or download the HTML files
2. Open any of the `.html` files directly in **Google Chrome** (voice features require mic access)
3. Try the features:
   - Open `index.html` to get supportive AI-driven responses
   - Use `journal.html` to speak and save your entries
   - Try `avatar.html` to generate a custom mood avatar

> No backend or installation required — this runs fully in-browser!

---

## Problem It Solves

- Mental health support is often inaccessible, costly, or intimidating
- People may not realize when they need help — or may not want to burden others
- BUDDY helps users reflect, express, and receive support in real time, privately and affordably

---

## Challenges

- Requires extensive research & refinement to ensure responsible feedback
- Cannot fully replace human empathy or clinical guidance
- Raises important concerns around data privacy and ethical AI use
- Risk of users becoming over-reliant without escalating to real-world care

---

## What Happens If This Problem is Ignored?

- Rising rates of untreated mental illness and suicide
- Increased school dropout, job loss, and long-term instability
- Strain on healthcare systems and deepening cycles of poverty
- Continued stigma and silence around mental well-being

---

## Live Demo

You can try the features live here:

`index.html` to get supportive AI-driven responses:  https://your-username.github.io/buddy/
 `journal.html` to speak and save your entries: 


